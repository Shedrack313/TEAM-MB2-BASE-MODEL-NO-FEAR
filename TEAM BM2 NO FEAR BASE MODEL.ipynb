{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7e849a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T09:24:53.643384Z",
     "start_time": "2021-06-11T09:24:53.622385Z"
    }
   },
   "source": [
    "# Regression Predict Student Solution\n",
    "\n",
    "© Explore Data Science Academy\n",
    "\n",
    "---\n",
    "### Honour Code\n",
    "\n",
    "I {**YOUR NAME, YOUR SURNAME**}, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the [EDSA honour code](https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract.\n",
    "\n",
    "### Predict Overview: Spain Electricity Shortfall Challenge\n",
    "\n",
    "The government of Spain is considering an expansion of it's renewable energy resource infrastructure investments. As such, they require information on the trends and patterns of the countries renewable sources and fossil fuel energy generation. Your company has been awarded the contract to:\n",
    "\n",
    "- 1. analyse the supplied data;\n",
    "- 2. identify potential errors in the data and clean the existing data set;\n",
    "- 3. determine if additional features can be added to enrich the data set;\n",
    "- 4. build a model that is capable of forecasting the three hourly demand shortfalls;\n",
    "- 5. evaluate the accuracy of the best machine learning model;\n",
    "- 6. determine what features were most important in the model’s prediction decision, and\n",
    "- 7. explain the inner working of the model to a non-technical audience.\n",
    "\n",
    "Formally the problem statement was given to you, the senior data scientist, by your manager via email reads as follow:\n",
    "\n",
    "> In this project you are tasked to model the shortfall between the energy generated by means of fossil fuels and various renewable sources - for the country of Spain. The daily shortfall, which will be referred to as the target variable, will be modelled as a function of various city-specific weather features such as `pressure`, `wind speed`, `humidity`, etc. As with all data science projects, the provided features are rarely adequate predictors of the target variable. As such, you are required to perform feature engineering to ensure that you will be able to accurately model Spain's three hourly shortfalls.\n",
    " \n",
    "On top of this, she has provided you with a starter notebook containing vague explanations of what the main outcomes are. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05600c92",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#four>4. Data Engineering</a>\n",
    "\n",
    "<a href=#five>5. Modeling</a>\n",
    "\n",
    "<a href=#six>6. Model Performance</a>\n",
    "\n",
    "<a href=#seven>7. Model Explanations</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997462e2",
   "metadata": {},
   "source": [
    " <a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Importing Packages ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to import, and briefly discuss, the libraries that will be used throughout your analysis and modelling. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "475dbe93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:30:53.800892Z",
     "start_time": "2021-06-23T10:30:50.215449Z"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries for data loading, data manipulation and data visulisation\n",
    "import pandas as pd               #For data loading and data manipulation\n",
    "import seaborn as sns             #For data visualization \n",
    "import matplotlib.pyplot as plt   #For data visualization \n",
    "from matplotlib import rc\n",
    "\n",
    "# Libraries for data preparation and model building\n",
    "import numpy as np               #for numerical and scientific computing\n",
    "from sklearn.linear_model import LinearRegression  #for building Linear regression model\n",
    "from sklearn.model_selection import train_test_split #for splitting the data\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a6718",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Loading the data ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to load the data from the `df_train` file into a DataFrame. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbbb6c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:49:35.311495Z",
     "start_time": "2021-06-28T08:49:35.295494Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "df_train = pd.read_csv(\"https://raw.githubusercontent.com/Explore-AI/load-shortfall-regression-predict-api/master/utils/data/df_train.csv\")\n",
    "df_test = pd.read_csv(\"https://raw.githubusercontent.com/Explore-AI/load-shortfall-regression-predict-api/master/utils/data/df_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de9424ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train df: (8763, 49)\n",
      "Shape of test df: (2920, 48)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of train df: {df_train.shape}')\n",
    "print(f'Shape of test df: {df_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81132ab3",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 3. Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Exploratory data analysis ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to perform an in-depth analysis of all the variables in the DataFrame. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e805134e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:52:37.824204Z",
     "start_time": "2021-06-28T08:52:37.811206Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.head() #viewing the top 5rows of our train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a259dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe() # look at data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a19d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns #Visualizing all the columns in our training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0484a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info() #Visualizing the info of our training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04a0b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum() #Check for null values in our training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f84a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the number of null values in our Valencia_pressure column\n",
    "print(df_train.isnull().sum())\n",
    "print('\\n')\n",
    "print(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a471a148",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Valencia_pressure.describe()  #Exploring the statistics of the feature with null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa93ec6",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## 4. Data Engineering\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Data engineering ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to: clean the dataset, and possibly create new features - as identified in the EDA phase. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059c2f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the datatype of the time column to datetime\n",
    "df_train['time'] = pd.to_datetime(df_train['time'])\n",
    "df_test['time'] = pd.to_datetime(df_test['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a5954d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling null values\n",
    "mean_value_train = df_train['Valencia_pressure'].mean()\n",
    "df_train['Valencia_pressure'].fillna(mean_value_train,inplace=True)\n",
    "\n",
    "mean_value_test = df_test['Valencia_pressure'].mean()\n",
    "df_test['Valencia_pressure'].fillna(mean_value_test,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eea17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check our dataset for null values\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab193449",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for the Presence of Outliers with Kurtosis\n",
    "df_train.kurtosis()\n",
    "\n",
    "\"\"\"\n",
    "Features with kurtosis values indicate the presence of outliers \n",
    "From the above code we can see that Valencia_wind_speed, Bilbao_rain_1h,Barcelona_rain_1h,\n",
    "Seville_rain_1h, Madrid_rain_1h, Valencia_snow_3h all contain outliers\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9cb3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a histogram of our target variable\n",
    "sns.histplot(data=df_train, x='load_shortfall_3h',bins=10)\n",
    "plt.title('Distribution of Load Shortfall 3h');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7a0420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot heatmap to show correlation between the numeric variables\n",
    "fig = plt.figure(figsize=(30,25))\n",
    "\n",
    "sns.heatmap(df_train.corr(),annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4662f5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new features\n",
    "# extract year and month values from our time columne\n",
    "df_train['year'] = df_train['time'].dt.year\n",
    "df_test['year'] = df_test['time'].dt.year\n",
    "\n",
    "df_train['month'] = df_train['time'].dt.month\n",
    "df_test['month'] = df_test['time'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59692724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the time column\n",
    "df_train = df_train.drop('time',axis=1)\n",
    "df_test = df_test.drop('time',axis=1)\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b2d523",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. Modelling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Modelling ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to create one or more regression models that are able to accurately predict the thee hour load shortfall. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2344b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into features and label\n",
    "X = df_train.drop('load_shortfall_3h',axis=1)\n",
    "y = df_train['load_shortfall_3h'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c58df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create targets and features dataset\n",
    "selector = SelectKBest(chi2, k=10)\n",
    "fit = selector.fit(X,y)\n",
    "scores = pd.DataFrame(fit.scores_)\n",
    "columns = pd.DataFrame(X.columns)\n",
    "featureScores = pd.concat([columns, scores], axis=1)\n",
    "featureScores.columns = ['Features', 'Score']\n",
    "new_X = featureScores.sort_values('Score',ascending=False).head(40)\n",
    "new_X.tail(10)\n",
    "\n",
    "\"\"\"\n",
    "Using SelectKbest to select the Feature Selection \n",
    "finding top k features, by this see the ten most important\n",
    "features in the table based on the selectkbest model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43fdc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and validation\n",
    "X_train, X_val, y_train, y_val = df_train_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9e1d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize our numerical data\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72c37c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform the data\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31e322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the new dataframe with the scaled data\n",
    "X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "X_val = pd.DataFrame(X_val, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c12178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one or more ML models\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0bf895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the linear regression model with test data\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7f7b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the linear regressor\n",
    "lr_pred = lr.predict(X_val)\n",
    "lr_mse = mean_squared_error(y_val, lr_pred)\n",
    "lr_r2 = r2_score(y_val, lr_pred)\n",
    "lr_mae = mean_absolute_error(y_val, lr_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d073e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create more ML models. Train, fit, predict and evaluate also the following models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2086ff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#support vector model\n",
    "svm = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ad86d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest regressor\n",
    "rfr = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d59db92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision tree regressor\n",
    "dtr = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b530251",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Model Performance\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model performance ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to compare the relative performance of the various trained ML models on a holdout dataset and comment on what model is the best and why. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance. Given the following metrics we will be comparing the model performance based on:    \n",
    "Mean Squared Error\n",
    "Mean Absolute Error\n",
    "R-squared score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3874a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose best model and motivate why it is the best choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad0c0d",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "## 7. Model Explanations\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model explanation ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to discuss how the best performing model works in a simple way so that both technical and non-technical stakeholders can grasp the intuition behind the model's inner workings. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff741c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discuss chosen methods logic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
